{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tbeucler/2024_UNIL_Geoinformatique/blob/main/Geoinformatique_I/IP/Tutoriel_IP/S3_IP_tutoriel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutoriel 3: Structure de donn√©es\n",
    "\n",
    "Dans cette section, nous aborderons les points suivants:\n",
    "\n",
    "1. File I/O\n",
    "2. List\n",
    "3. Tuples\n",
    "4. Sets\n",
    "5. Dictionnaires\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O\n",
    "Dans cette section, nous pr√©senterons les fonctions de base que nous pouvons utiliser pour stocker et r√©cup√©rer des donn√©es √† partir de fichiers de diff√©rents formats.\n",
    "\n",
    "Pour les projets en sciences de l'environnement, les donn√©es de recherche sont le plus souvent stock√©es dans les formats suivants :\n",
    "1.   Fichiers texte (`TXT`)\n",
    "2.   Fichiers tabulaires (par exemple, `CSV`, `XLS`)\n",
    "3.   Donn√©es structur√©es / dictionnaires Python, etc. (par exemple, `Pickle`, `dill`, `JSON`)\n",
    "4.   Donn√©es maill√©es (par exemple, `HDF5`, `NetCDF`)\n",
    "\n",
    "Nous allons maintenant voir comment nous pouvons utiliser Python et diff√©rents paquets Python pour r√©cup√©rer les donn√©es stock√©es dans ces formats, et comment sauvegarder vos donn√©es dans diff√©rents formats pour une utilisation ult√©rieure.\n",
    "\n",
    "R√©f√©rence:\n",
    "*   CUSP UCSL bootcamp 2017 (https://github.com/Mohitsharma44/ucsl17)\n",
    "*   Python 3 tutorial (https://docs.python.org/3/tutorial/inputoutput.html)\n",
    "*   GSFC Python Bootcamp (https://github.com/astg606/py_materials/blob/master/useful_modules/)\n",
    "*   Working on JSON Data in Python (https://realpython.com/python-json/)\n",
    "*   PyHOGS (http://pyhogs.github.io/intro_netcdf4.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commen√ßons par importer quelques paquets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import netCDF4\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fichiers TXT\n",
    "Nous allons maintenant apprendre √† √©crire des informations dans un fichier .TXT et √† les relire √† l'aide de fonctions Python int√©gr√©es. Les donn√©es utilis√©es dans cette partie du tutoriel seront tr√®s simples. Dans les prochains exercices, nous pr√©senterons √©galement les commandes des paquets communautaires qui nous permettent de lire et de stocker des donn√©es plus complexes.\n",
    "\n",
    "#### Ouverture de fichiers :\n",
    "Les fichiers peuvent √™tre ouverts en utilisant la fonction int√©gr√©e de Python `open()`. Cette fonction cr√©e un objet fichier pour les op√©rations suivantes. Utilisez la syntaxe suivante pour lire un fichier TXT : \\\\\n",
    "`fhandler = open(file_name, access mode, encoding)`\n",
    "\n",
    "- `nom_du_fichier` : Le nom du fichier sur lequel vous souhaitez effectuer vos op√©rations d'E/S. \\\n",
    "Notez qu'il s'agit du chemin d'acc√®s complet au fichier (par exemple, $\\text{\\\\home\\\\Documents\\\\file.txt}$ )\n",
    "- `encodage` : Sch√©ma d'encodage √† utiliser pour convertir le flux d'octets en texte. (Standard=`utf-8`)\n",
    "- `access_mode` : La fa√ßon dont un fichier est ouvert, les choix disponibles pour cette option incluent :\n",
    "\n",
    "|access_mode | Its Function|\n",
    "|:------|------------:|\n",
    "|r\t|Ouvre un fichier en lecture seule|\n",
    "|rb\t|Ouvre un fichier en lecture seule au format binaire|\n",
    "|r+\t|Ouvre un fichier pour la lecture et l'√©criture|\n",
    "|rb+\t|Ouvre un fichier pour la lecture et l'√©criture au format binaire|\n",
    "|w\t|Ouvre un fichier en √©criture uniquement|\n",
    "|wb\t|Ouvre un fichier en √©criture uniquement au format binaire|\n",
    "|w+\t|Ouvre un fichier en lecture et en √©criture|\n",
    "|wb+\t|Ouvre un fichier pour l'√©criture et la lecture au format binaire|\n",
    "|a\t|Ouvre un fichier pour l'ajouter|\n",
    "|ab\t|Ouvre un fichier pour l'ajouter en binaire|\n",
    "|a+\t|Ouvre un fichier pour l'ajout et la lecture|\n",
    "|ab+\t|Ouvre un fichier pour l'ajout et la lecture au format binaire|\n",
    "\n",
    "Dans l'exemple ci-dessous, nous allons essayer de stocker plusieurs phrases dans un nouveau fichier TXT, et utiliser la fonction `open()` pour voir si le code fonctionne comme pr√©vu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhandler = open('test.txt', 'w', encoding=\"utf-8\")\n",
    "fhandler.write('Hello World!\\n')\n",
    "fhandler.write('I am a UNIL Master Student.\\n')\n",
    "fhandler.write('I am learning how to code!\\n')\n",
    "fhandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "In the code above, we use the `open()` command to create a *write-only* (`access_mode='w'`) file `test.txt`. The open command creates a file object (`fhandler`) on which we can perform extra operations.\n",
    "\n",
    "We then try to add three sentences to the TXT file using the `.write()` operation on the file object.\n",
    "\n",
    "Remember to close the file with `.close()` command so that the changes can be finalized!\n",
    "\n",
    "If the code is writing, we should see a `test.txt` file created in the same path as this notebook. Let's see if that's the case!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourra ! √áa marche ! üòÄ\n",
    "\n",
    "Mais n'avons-nous pas dit que nous voulions le relire ? ü§®\n",
    "\n",
    "Essayons de lire le fichier alors ! Pouvez-vous penser √† des fa√ßons de le faire ?\n",
    "\n",
    "Voici quelques-unes des fonctions que vous pourriez utiliser.\n",
    "\n",
    "1.   `.close()` : Ferme le fichier actuellement ouvert.\n",
    "2.   `.readline([size])` : Lit les cha√Ænes de caract√®res d'un fichier jusqu'√† ce qu'il atteigne le caract√®re de nouvelle ligne `\\n` si le param√®tre `size` est vide. Sinon, il lira la cha√Æne de caract√®res de la taille donn√©e.\n",
    "3.   `.readlines([size])` : Appelle r√©p√©titivement `.readline()` jusqu'√† la fin du fichier.\n",
    "4.   `.write(str)` : √âcrit la cha√Æne de caract√®res str dans le fichier.\n",
    "5.   `.writelines([list])` : Ecrit une s√©quence de cha√Ænes de caract√®res dans un fichier. Aucune nouvelle ligne n'est ajout√©e automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhandler = open('test.txt','r',encoding='utf-8')\n",
    "fhandler.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et si nous voulions ajouter du texte au fichier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'r+') as fhandler:\n",
    "  print(fhandler.readlines())\n",
    "  fhandler.writelines(['Now,\\n', 'I am trying to', ' add some stuff.'])\n",
    "  # Go to the starting of file\n",
    "  fhandler.seek(0)\n",
    "  # Print the content of file\n",
    "  print(fhandler.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous utilisons une autre m√©thode pour ouvrir et √©crire le fichier de donn√©es.\n",
    "En utilisant l'instruction `with` pour ouvrir le fichier TXT, nous nous assurons que les donn√©es sont automatiquement ferm√©es apr√®s l'op√©ration finale. Nous n'avons plus besoin d'√©crire l'instruction `fhandler.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fichiers tabulaires\n",
    "Que feriez-vous si vous aviez des donn√©es joliment organis√©es dans le format ci-dessous ?\n",
    "```\n",
    "Donn√©es1, Donn√©es2, Donn√©es3\n",
    "Exemple01, Exemple02, Exemple03\n",
    "Exemple11, Exemple12, Exemple13\n",
    "```\n",
    "Lorsque vous ouvrez un fichier de ce type dans Excel, voici √† quoi il ressemble :\n",
    "\n",
    "||||\n",
    "|:--|:--|:--|\n",
    "|Donn√©e1\t|Donn√©e2\t|Donn√©e3|\n",
    "|Exemple1\t|Exemple2\t|Exemple3|\n",
    "\n",
    "Il s'agit d'un fichier tabulaire _s√©par√© par des virgules_. Les fichiers de ce type sont g√©n√©ralement enregistr√©s avec l'extension `.csv`. Les fichiers `.csv` peuvent ensuite √™tre ouverts et visualis√©s √† l'aide d'un tableur, tel que Google Sheets, Numbers ou Microsoft Excel.\n",
    "\n",
    "Mais qu'en est-il si nous voulons utiliser les donn√©es dans Python ?\n",
    "\n",
    "#### Ouverture des fichiers :\n",
    "Heureusement, il existe des paquets communautaires qui peuvent vous aider √† importer et √† r√©cup√©rer vos donn√©es tabulaires avec un minimum d'effort. Nous pr√©sentons ici deux de ces packages : CSV et Pandas.\n",
    "\n",
    "##### Lire des fichiers CSV avec le paquetage `CSV`\n",
    "\n",
    "`reader()` peut √™tre utilis√© pour cr√©er un objet qui est utilis√© pour lire les donn√©es d'un fichier CSV. Le lecteur peut √™tre utilis√© comme un it√©rateur pour traiter les lignes du fichier dans l'ordre. Voyons un exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch\n",
    "import urllib.request\n",
    "datafile = pooch.retrieve('https://unils-my.sharepoint.com/:x:/g/personal/tom_beucler_unil_ch/ETDZdgCkWbZLiv_LP6HKCOAB2NP7H0tUTLlP_stknqQHGw?download=1',\n",
    "                          known_hash='c7676360997870d00a0da139c80fb1b6d26e1f96050e03f2fed75b921beb4771')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = []\n",
    "# https://unils-my.sharepoint.com/:x:/g/personal/tom_beucler_unil_ch/ETDZdgCkWbZLiv_LP6HKCOAB2NP7H0tUTLlP_stknqQHGw?e=N541Yq\n",
    "with open(datafile, 'r') as fh:\n",
    "  reader = csv.reader(fh)\n",
    "  for info in reader:\n",
    "    row.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``{tip}\n",
    "Dans le code ci-dessus, nous utilisons la m√©thode `csv.reader()` pour lire it√©rativement chaque ligne du fichier CSV.\n",
    "\n",
    "Nous ajoutons une nouvelle ligne √† une liste vide √† chaque it√©ration.\n",
    "\n",
    "Nous utilisons la fonction `print()` pour voir ce qui a √©t√© √©crit dans la liste. Nous avons constat√© que la premi√®re ligne contient des informations sur les noms de variables, tandis que la deuxi√®me ligne contient des donn√©es √† un pas de temps donn√©.\n",
    "```\n",
    "\n",
    "#### Extraire les donn√©es et les √©crire dans un nouveau fichier CSV :\n",
    "Le fichier CSV que nous venons d'importer contient en fait les donn√©es des stations m√©t√©orologiques de janvier 2022 √† ao√ªt 2022. Que se passe-t-il si nous ne voulons que les donn√©es des cinq premi√®res lignes ? Pouvons-nous extraire les donn√©es et les enregistrer dans un nouveau fichier CSV ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testsmall.csv', 'w') as fh:\n",
    "  writer = csv.writer(fh)\n",
    "  for num in range(5):\n",
    "    writer.writerow(row[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "\n",
    "En fait, il existe un meilleur paquetage pour les donn√©es tabulaires. Cette biblioth√®que s'appelle `Pandas`. Nous pr√©senterons ce paquetage plus en d√©tail la semaine prochaine. Pour l'instant, nous allons simplement d√©montrer que nous pouvons utiliser pandas pour faire la m√™me proc√©dure FileI/O que nous avons faite plus t√¥t avec CSV.\n",
    "\n",
    "Ici, nous lisons la grande feuille de donn√©es de la station m√©t√©orologique `datafile` avec la fonction pandas `.read_csv()`.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importer fichier CSV avec pandas\n",
    "ALOdatasheet = pd.read_csv(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter les cinq premi√®res lignes du cadre de donn√©es Pandas vers un fichier CSV\n",
    "ALOdatasheet[0:5].to_csv('./testsmall_pd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S√©rialisation et d√©s√©rialisation avec Pickle\n",
    "(R√©√©crit √† partir du GSFC Python Bootcamp)\n",
    "\n",
    "Pickle est un format interne de Python qui permet d'√©crire des donn√©es arbitraires dans un fichier de mani√®re √† pouvoir les relire, intactes.\n",
    "* `pickle` \"s√©rialise\" d'abord l'objet avant de l'√©crire dans un fichier.\n",
    "* Le d√©capage (s√©rialisation) est un moyen de convertir un objet Python (liste, dict, etc.) en un flux de caract√®res qui contient toutes les informations n√©cessaires pour reconstruire l'objet dans un autre script Python.\n",
    "\n",
    "Les types suivants peuvent √™tre s√©rialis√©s et d√©s√©rialis√©s en utilisant le module `pickle` :\n",
    "* Tous les types de donn√©es natifs support√©s par Python (bool√©ens, None, entiers, flottants, nombres complexes, cha√Ænes de caract√®res, octets, tableaux d'octets).\n",
    "* Dictionnaires, ensembles, listes et tuples - tant qu'ils contiennent des objets s√©lectionnables.\n",
    "* Les fonctions (d√©crypt√©es par leur nom de r√©f√©rence, et non par leur valeur) et les classes qui sont d√©finies au niveau sup√©rieur d'un module.\n",
    "\n",
    "Les fonctions principales de `pickle` sont :\n",
    "\n",
    "* `dump()` : r√©cup√®re des donn√©es en acceptant des donn√©es et un objet fichier.\n",
    "* `load()` : prend un objet fichier, reconstruit les objets √† partir de la repr√©sentation d√©cap√©e, et les renvoie.\n",
    "* `dumps()` : renvoie les donn√©es d√©crypt√©es sous forme de cha√Æne de caract√®res.\n",
    "* `loads()` : lit les donn√©es extraites d'une cha√Æne.\n",
    "\n",
    "`dump()`/`load()` s√©rialise/d√©s√©rialise les objets √† travers des fichiers mais `dumps()`/`loads()` s√©rialise/d√©s√©rialise les objets √† travers une repr√©sentation sous forme de cha√Æne de caract√®res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de dictionnaire Python\n",
    "data_org = { 'mydata1':np.linspace(0,800,801), 'mydata2':np.linspace(0,60,61)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer un dictionnaire Python dans un fichier pickle\n",
    "with open('pickledict_sample.pkl', 'wb') as fid:\n",
    "     pickle.dump(data_org, fid)\n",
    "# Deserialize saved pickle file\n",
    "with open('pickledict_sample.pkl', 'rb') as fid:\n",
    "     data3 = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for strg in data_org.keys():\n",
    "  print(f\"Variable {strg} is the same in data_org and data3: {(data_org[strg]==data3[strg]).all()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bonus**\n",
    "\n",
    "Nous avons d√©j√† abord√© un grand nombre de sujets en une journ√©e, mais votre professeur a √©galement r√©dig√© des instructions sur la lecture et l'√©criture de donn√©es dans d'autres formats ! Le tutoriel suivant sera donc laiss√© √† votre disposition pour que vous puissiez l'exp√©rimenter chez vous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donn√©es structur√©es avec JSON\n",
    "JSON est un format populaire pour les donn√©es structur√©es qui peut √™tre utilis√© dans Python et Perl, entre autres langages.\n",
    "Le format JSON est construit sur une collection de paires nom/valeur. Les informations sur le nom peuvent √™tre un objet, un enregistrement, un dictionnaire, une table de hachage, une liste √† cl√©s ou un tableau associatif. La valeur associ√©e au nom peut √™tre un tableau, un vecteur, une liste ou une s√©quence.\n",
    "\n",
    "Nous pouvons utiliser le paquetage `json` pour les entr√©es-sorties. La syntaxe du paquet est tr√®s similaire √† celle de `pickle` :\n",
    "\n",
    "* `dump()` : √©criture d'une cha√Æne encod√©e dans un fichier.\n",
    "* `load()` : D√©codage lors de la lecture d'un fichier JSON.\n",
    "* `dumps()` : encodage en objets JSON\n",
    "* `loads()` : D√©code la cha√Æne JSON.\n",
    "\n",
    "**Exemple de donn√©es JSON**\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"stations\" : [\n",
    "        {\n",
    "            \"acronyme\" : \"BLD\",\n",
    "            \"nom\" : \"Boulder Colorado\",\n",
    "            \"latitude\" : 40.00,\n",
    "            \"longitude\" : -105.25\n",
    "        },\n",
    "        {\n",
    "            \"acronyme\" : \"BHD\",\n",
    "            \"name\" : \"Baring Head Wellington New Zealand\",\n",
    "            \"latitude\" : -41.28,\n",
    "            \"longitude\" : 174.87\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de lire ce cadre de donn√©es JSON avec `json` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_data = '{\"stations\": [{\"acronym\": \"BLD\", \\\n",
    "                                \"nom\": \"Boulder Colorado\", \\\n",
    "                            \"latitude\": 40.00, \\\n",
    "                            \"longitude\": -105.25}, \\\n",
    "                            {\"acronym\": \"BHD\", \\\n",
    "                             \"nom\": \"Baring Head Wellington New Zealand\",\\\n",
    "                             \"latitude\": -41.28, \\\n",
    "                             \"longitude\": 174.87}]}'\n",
    "\n",
    "python_obj = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boulder Colorado\n",
      "Baring Head Wellington New Zealand\n"
     ]
    }
   ],
   "source": [
    "for x in python_obj['stations']:\n",
    "    print(x[\"nom\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertir python_obj en JSON\n",
    "print(json.dumps(python_obj, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant essayer de convertir un objet python en JSON et de l'√©crire dans un fichier.\n",
    "La syntaxe pour la s√©rialisation et la d√©s√©rialisation dans le paquet `json` est presque la m√™me que celle de `pickle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les objets python en JSON\n",
    "x = {\n",
    "  \"pr√©nom\" : \"John\",\n",
    "  \"√¢ge\" : 30,\n",
    "  \"mari√©\" : True,\n",
    "  \"divorc√©\" : False,\n",
    "  \"enfants\" : (\"Ann\", \"Billy\"),\n",
    "  \"animaux\" : None,\n",
    "  \"voitures\" : [\n",
    "    {\"mod√®le\" : \"BMW 230\", \"mpg\" : 27.5},\n",
    "    {\"Mod√®le\" : \"Ford Edge\", \"mpg\" : 24.1}\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr√©nom': 'John', '√¢ge': 30, 'mari√©': True, 'divorc√©': False, 'enfants': ['Ann', 'Billy'], 'animaux': None, 'voitures': [{'mod√®le': 'BMW 230', 'mpg': 27.5}, {'Mod√®le': 'Ford Edge', 'mpg': 24.1}]}\n"
     ]
    }
   ],
   "source": [
    "# S√©rialisation\n",
    "with open('./pythonobj.json','w') as sid :\n",
    "  json.dump(x,sid)\n",
    "# D√©s√©rialisation\n",
    "with open('./pythonobj.json', 'r') as sid :\n",
    "  z = json.load(sid)\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donn√©es quadrill√©es √† N dimensions avec NetCDF4\n",
    "Les jeux de donn√©es g√©oscientifiques contiennent souvent plusieurs dimensions. Par exemple, les r√©sultats des mod√®les climatiques contiennent g√©n√©ralement 4 dimensions : le temps (t), le niveau vertical (z), la longitude (lon) et la latitude (lat). Ces donn√©es sont trop complexes pour √™tre stock√©es dans des tableaux.\n",
    "\n",
    "D√©velopp√© par _Unidata_ (une filiale de UCAR), le format NetCDF contient une structure hi√©rarchique qui permet une meilleure organisation et un meilleur stockage de grands ensembles de donn√©es multidimensionnelles, d'informations sur les axes et d'autres m√©tadonn√©es. Il est bien adapt√© √† la gestion de grands ensembles de donn√©es num√©riques, car il permet aux utilisateurs d'acc√©der √† des parties d'un ensemble de donn√©es sans avoir √† le charger enti√®rement en m√©moire.\n",
    "\n",
    "Nous pouvons utiliser le paquetage `netCDF4` pour cr√©er, lire et stocker des donn√©es dans NetCDF4. Un autre paquetage, `xarray`, est √©galement disponible pour ce format de donn√©es.\n",
    "\n",
    "#### **Voici comment vous cr√©ez et stockez normalement des donn√©es dans un fichier netCDF:**\n",
    "\n",
    "\n",
    "1.   Ouvrez/cr√©ez un jeu de donn√©es netCDF.\n",
    "2.   D√©finissez les dimensions des donn√©es.\n",
    "3.   Construire des variables netCDF en utilisant les dimensions d√©finies.\n",
    "4.   Transf√©rer les donn√©es dans les variables netCDF.\n",
    "5.   Ajouter des attributs aux variables et √† l'ensemble de donn√©es (facultatif mais recommand√©).\n",
    "6.   Fermez le jeu de donn√©es netCDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ouvrir un jeu de donn√©es netCDF4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfid = netCDF4.Dataset('sample_netcdf.nc', mode='w', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`modeType` a les options suivantes :\n",
    "* 'w' : pour cr√©er un nouveau fichier\n",
    "* 'r+' : pour lire et √©crire dans un fichier existant\n",
    "* 'r' : pour lire (uniquement) un fichier existant\n",
    "* 'a' : pour ajouter un fichier √† un fichier existant\n",
    "\n",
    "`fileFormat` a les options suivantes :\n",
    "* 'NETCDF3_CLASSIC' : Format netCDF original     \n",
    "* 'NETCDF3_64BIT_OFFSET' : Utilis√© pour all√©ger les restrictions de taille des fichiers netCDF classiques.\n",
    "* 'NETCDF4_CLASSIC'\n",
    "* 'NETCDF4' : Offre de nouvelles fonctionnalit√©s telles que les groupes, les types compos√©s, les tableaux de longueur variable, les nouveaux types d'entiers non sign√©s, l'acc√®s parall√®le aux E/S, etc.\n",
    "* 'NETCDF3_64BIT_DATA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Cr√©ation de dimensions dans un fichier netCDF</font>**\n",
    "* D√©clarez les dimensions avec `.createDimension(size)`\n",
    "* Pour des dimensions illimit√©es, utilisez `None` ou `0` comme taille.\n",
    "* Les dimensions de taille illimit√©e doivent √™tre d√©clar√©es avant (\"√† gauche de\") les autres dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les dimensions des donn√©es\n",
    "time = ncfid.createDimension('time', None)\n",
    "lev = ncfid.createDimension('lev', 72)\n",
    "lat = ncfid.createDimension('lat', 91)\n",
    "lon = ncfid.createDimension('lon', 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Cr√©er des variables de dimension et des variables de donn√©es pr√©-remplies avec fill_value\n",
    "##########################################################################################\n",
    "# Variables de dimension\n",
    "times = ncfid.createVariable('time','f8',('time',))\n",
    "levels = ncfid.createVariable('lev','i4',('lev',))\n",
    "latitudes = ncfid.createVariable('lat','f4',('lat',))\n",
    "longitudes = ncfid.createVariable('lon','f4',('lon',))\n",
    "# Variable de donn√©es pr√©-remplie\n",
    "temp = ncfid.createVariable('temp','f4',\n",
    "                            ('time', 'lev', 'lat', 'lon',),\n",
    "                            fill_value=1.0e15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ajouter des attributs variables</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "latitudes.long_name = 'latitude'\n",
    "latitudes.units = 'degr√©s nord'\n",
    "\n",
    "longitudes.nom_long = 'longitude'\n",
    "longitudes.units = 'degr√©s est'\n",
    "\n",
    "levels.long_name = 'niveaux verticaux'\n",
    "levels.units = 'hPa'\n",
    "levels.positive = 'down'\n",
    "\n",
    "beg_date = datetime.datetime(year=2019, month=1, day=1)\n",
    "times.long_name = 'temps'\n",
    "times.units = beg_date.strftime('heures depuis %Y-%m-%d %H:%M:%S')\n",
    "times.calendar = 'gregorian'\n",
    "\n",
    "temp.long_name = 'temp√©rature'\n",
    "temp.units = 'K'\n",
    "temp.nom_standard = 'temp√©rature_atmosph√©rique'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **√âcrire des donn√©es dans un fichier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes[ :] = np.arange(-90,91,2.0)\n",
    "longitudes[ :] = np.arange(-180,180,2.5)\n",
    "levels[ :] = np.arange(0,72,1)\n",
    "\n",
    "out_frequency = 3 # fr√©quence de sortie en heures\n",
    "num_records = 5\n",
    "dates = [beg_date + n*datetime.timedelta(hours=out_frequency) for n in range(num_records)]\n",
    "times[ :] = netCDF4.date2num(dates, units=times.units, calendar=times.calendar)\n",
    "for i in range(num_records) :\n",
    "    temp[i, :,:, :] = np.random.uniform(size=(levels.size,\n",
    "                                            latitudes.size,\n",
    "                                            longitudes.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nous allons maintenant lire le fichier netCDF4 stock√© pour voir ce que nous venons de faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databank = netCDF4.Dataset('./sample_netcdf.nc', mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous imprimons les noms des variables dans le fichier `sample_netcdf.nc`.\n",
    "print(databank.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous pouvons lire les donn√©es comme suit\n",
    "time   = ncfid.variables['time'][:]\n",
    "lev    = ncfid.variables['lev'][:]\n",
    "lat    = ncfid.variables['lat'][:]\n",
    "lon    = ncfid.variables['lon'][:]\n",
    "temp   = ncfid.variables['temp'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{important}\n",
    "\n",
    "Lors de la lecture de donn√©es √† partir d'un fichier :\n",
    "\n",
    "- Si vous n'incluez pas `[ :]` √† la fin de `variables[var_name]`, vous obtenez un objet variable.\n",
    "- Si vous incluez `[ :]` (ou `[ :,:]`, `[0, i:j, :]`, etc.) √† la fin de `variables[var_name]`, vous obtenez le tableau Numpy contenant les donn√©es.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionnaires"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
